{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8c9626ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: emoji in /usr/local/lib/python3.7/site-packages (2.8.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8bca4d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "43b1286b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>normalized_text_stemm_emoji</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-04 22:17:21</td>\n",
       "      <td>RT @emirsader: Ap√≥s ficar em sil√™ncio na CPI d...</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>[ap√≥s, fic, sil√™nci, cpi, carl, wizard, retorn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-30 14:35:33</td>\n",
       "      <td>RT @VittorGuidoni: para de lamber fone de ouvi...</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>[lamb, fon, ouv, list, doen√ß, transmiss, oral,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-11 12:12:28</td>\n",
       "      <td>@exposed_exposer @CarlaZambelli38 @andrizek De...</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>[defin, vacin, tip, subst, bact√©r, introduz, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-11-19 14:52:06</td>\n",
       "      <td>RT @canaltech: Por que o iPhone √© mais seguro ...</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>[iphon, segur, contr, ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-12-28 23:09:10</td>\n",
       "      <td>RT @mariareinhardtt: covid t√° a estragar compl...</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>[estrag, complet, tud, ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            created_at                                               text  \\\n",
       "0  2021-07-04 22:17:21  RT @emirsader: Ap√≥s ficar em sil√™ncio na CPI d...   \n",
       "1  2019-11-30 14:35:33  RT @VittorGuidoni: para de lamber fone de ouvi...   \n",
       "2  2022-01-11 12:12:28  @exposed_exposer @CarlaZambelli38 @andrizek De...   \n",
       "3  2019-11-19 14:52:06  RT @canaltech: Por que o iPhone √© mais seguro ...   \n",
       "4  2021-12-28 23:09:10  RT @mariareinhardtt: covid t√° a estragar compl...   \n",
       "\n",
       "  sentiment                        normalized_text_stemm_emoji  \n",
       "0  Positivo  [ap√≥s, fic, sil√™nci, cpi, carl, wizard, retorn...  \n",
       "1  Negativo  [lamb, fon, ouv, list, doen√ß, transmiss, oral,...  \n",
       "2  Negativo  [defin, vacin, tip, subst, bact√©r, introduz, c...  \n",
       "3  Positivo                            [iphon, segur, contr, ]  \n",
       "4  Negativo                           [estrag, complet, tud, ]  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data_pt_brazil_normalized_emoji_merged.csv',\n",
    "                                converters={\n",
    "                     \"normalized_text_stemm_emoji\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \")\n",
    "                 })\n",
    "df = df[['created_at', 'text', 'sentiment', 'normalized_text_stemm_emoji']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b253e66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_bank = {\n",
    "  \",:(\": \"üòì\",\n",
    "  \",:)\": \"üòÖ\",\n",
    "  \",:-(\": \"üòì\",\n",
    "  \",:-)\": \"üòÖ\",\n",
    "  \"0:)\": \"üòá\",\n",
    "  \"0:-)\": \"üòá\",\n",
    "  \"8-)\": \"üòé\",\n",
    "  \":$\": \"üòí\",\n",
    "  \":'(\": \"üò¢\",\n",
    "  \":')\": \"üòÇ\",\n",
    "  \":'-(\": \"üò¢\",\n",
    "  \":'-)\": \"üòÇ\",\n",
    "  \":'-D\": \"üòÇ\",\n",
    "  \":'D\": \"üòÇ\",\n",
    "  \":(\": \"üò¶\",\n",
    "  \":)\": \"üòÉ\",\n",
    "  \":*\": \"üòó\",\n",
    "  \":,'(\": \"üò≠\",\n",
    "  \":,'-(\": \"üò≠\",\n",
    "  \":,(\": \"üò¢\",\n",
    "  \":,)\": \"üòÇ\",\n",
    "  \":,-(\": \"üò¢\",\n",
    "  \":,-)\": \"üòÇ\",\n",
    "  \":,-D\": \"üòÇ\",\n",
    "  \":,D\": \"üòÇ\",\n",
    "  \":-$\": \"üòí\",\n",
    "  \":-(\": \"üò¶\",\n",
    "  \":-)\": \"üòÉ\",\n",
    "  \":-*\": \"üòó\",\n",
    "  \":-/\": \"üòï\",\n",
    "  \":-@\": \"üò°\",\n",
    "  \":-D\": \"üòÑ\",\n",
    "  \":-o\": \"üòÆ\",\n",
    "  \":-O\": \"üòÆ\",\n",
    "  \":-P\": \"üòõ\",\n",
    "  \":-S\": \"üòí\",\n",
    "  \":-Z\": \"üòí\",\n",
    "  \":-|\": \"üòê\",\n",
    "  \":/\": \"üòï\",\n",
    "  \":@\": \"üò°\",\n",
    "  \":D\": \"üòÑ\",\n",
    "  \":o\": \"üòÆ\",\n",
    "  \":O\": \"üòÆ\",\n",
    "  \":P\": \"üòõ\",\n",
    "  \":s\": \"üòí\",\n",
    "  \":z\": \"üòí\",\n",
    "  \":|\": \"üòê\",\n",
    "  \";(\": \"üò≠\",\n",
    "  \";)\": \"üòâ\",\n",
    "  \";-(\": \"üò≠\",\n",
    "  \";-)\": \"üòâ\",\n",
    "  \"]:)\": \"üòà\",\n",
    "  \"]:-)\": \"üòà\",\n",
    "  \"B-)\": \"üòé\",\n",
    "  \"o:)\": \"üòá\",\n",
    "  \"O:)\": \"üòá\",\n",
    "  \"O:-)\": \"üòá\",\n",
    "  \"o:-)\": \"üòá\",\n",
    "  \"X-)\": \"üòÜ\",\n",
    "  \"x-)\": \"üòÜ\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "26621668",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = ['rt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9bcfd786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string, unicodedata\n",
    "import nltk\n",
    "import emoji\n",
    "\n",
    "def extract_emojis(sample):\n",
    "    return ' '.join(c for c in sample if c in emoji.EMOJI_DATA).split()\n",
    "\n",
    "def remove_user_from_text(words):\n",
    "    return \" \".join(filter(lambda x:x[0]!='@', words.split()))\n",
    "\n",
    "def remove_double_space(sample):\n",
    "    return \" \".join(sample.split())\n",
    "\n",
    "def remove_URL(sample):\n",
    "    \"\"\"Remove URLs from a sample string\"\"\"\n",
    "    return re.sub(r\"http\\S+\", \"\", sample)\n",
    "\n",
    "def to_lowercase(words):\n",
    "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
    "    return list(map(lambda x: x.lower(), words))\n",
    "\n",
    "def remove_punctuation(words):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def clean_text(sample):\n",
    "    emoji_pat = '[\\U0001F300-\\U0001F64F\\U0001F680-\\U0001F6FF\\u2600-\\u26FF\\u2700-\\u27BF]'\n",
    "    shrink_whitespace_reg = re.compile(r'\\s{2,}')\n",
    "    reg = re.compile(r'({})|[^a-zA-Z]'.format(emoji_pat)) # line a\n",
    "    result = reg.sub(lambda x: ' {} '.format(x.group(1)) if x.group(1) else ' ', sample)\n",
    "    return shrink_whitespace_reg.sub(' ', result)\n",
    "\n",
    "def replace_asci_emoji(sample):\n",
    "    address = sample\n",
    "    for k,v in emoji_bank.items():\n",
    "        address = address.replace(k, v)\n",
    "    return address\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stopwords_list:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def normalize(words):\n",
    "    words = remove_user_from_text(words)\n",
    "    words = to_lowercase(words.split())\n",
    "    words = remove_punctuation(words)\n",
    "    words = remove_stopwords(words)\n",
    "    return words\n",
    "\n",
    "def preprocess(sample):\n",
    "    sample = remove_URL(sample)\n",
    "    sample = replace_asci_emoji(sample)\n",
    "#     sample = clean_text(sample)\n",
    "    sample = remove_double_space(sample)\n",
    "    return normalize(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "379b391a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>normalized_text_stemm_emoji</th>\n",
       "      <th>normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-04 22:17:21</td>\n",
       "      <td>RT @emirsader: Ap√≥s ficar em sil√™ncio na CPI d...</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>[ap√≥s, fic, sil√™nci, cpi, carl, wizard, retorn...</td>\n",
       "      <td>ap√≥s ficar em sil√™ncio na cpi da covid carlos ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-30 14:35:33</td>\n",
       "      <td>RT @VittorGuidoni: para de lamber fone de ouvi...</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>[lamb, fon, ouv, list, doen√ß, transmiss, oral,...</td>\n",
       "      <td>para de lamber fone de ouvido lista de doen√ßas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-11 12:12:28</td>\n",
       "      <td>@exposed_exposer @CarlaZambelli38 @andrizek De...</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>[defin, vacin, tip, subst, bact√©r, introduz, c...</td>\n",
       "      <td>defini√ß√£o de vacina √© um tipo de subst√¢ncia v√≠...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-11-19 14:52:06</td>\n",
       "      <td>RT @canaltech: Por que o iPhone √© mais seguro ...</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>[iphon, segur, contr, ]</td>\n",
       "      <td>por que o iphone √© mais seguro contra v√≠rus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-12-28 23:09:10</td>\n",
       "      <td>RT @mariareinhardtt: covid t√° a estragar compl...</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>[estrag, complet, tud, ]</td>\n",
       "      <td>covid t√° a estragar completamente tudo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            created_at                                               text  \\\n",
       "0  2021-07-04 22:17:21  RT @emirsader: Ap√≥s ficar em sil√™ncio na CPI d...   \n",
       "1  2019-11-30 14:35:33  RT @VittorGuidoni: para de lamber fone de ouvi...   \n",
       "2  2022-01-11 12:12:28  @exposed_exposer @CarlaZambelli38 @andrizek De...   \n",
       "3  2019-11-19 14:52:06  RT @canaltech: Por que o iPhone √© mais seguro ...   \n",
       "4  2021-12-28 23:09:10  RT @mariareinhardtt: covid t√° a estragar compl...   \n",
       "\n",
       "  sentiment                        normalized_text_stemm_emoji  \\\n",
       "0  Positivo  [ap√≥s, fic, sil√™nci, cpi, carl, wizard, retorn...   \n",
       "1  Negativo  [lamb, fon, ouv, list, doen√ß, transmiss, oral,...   \n",
       "2  Negativo  [defin, vacin, tip, subst, bact√©r, introduz, c...   \n",
       "3  Positivo                            [iphon, segur, contr, ]   \n",
       "4  Negativo                           [estrag, complet, tud, ]   \n",
       "\n",
       "                                          normalized  \n",
       "0  ap√≥s ficar em sil√™ncio na cpi da covid carlos ...  \n",
       "1  para de lamber fone de ouvido lista de doen√ßas...  \n",
       "2  defini√ß√£o de vacina √© um tipo de subst√¢ncia v√≠...  \n",
       "3        por que o iphone √© mais seguro contra v√≠rus  \n",
       "4             covid t√° a estragar completamente tudo  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['normalized'] = df.apply(lambda x: \" \".join(preprocess(x['text'])), axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4396900d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "Negativo    93560\n",
       "Neutro      58975\n",
       "Positivo    47465\n",
       "dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('sentiment').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "10aced97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stem'] = df['normalized_text_stemm_emoji'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f9a926b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>normalized</th>\n",
       "      <th>normalized_text_stemm_emoji</th>\n",
       "      <th>stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-04 22:17:21</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>ap√≥s ficar em sil√™ncio na cpi da covid carlos ...</td>\n",
       "      <td>[ap√≥s, fic, sil√™nci, cpi, carl, wizard, retorn...</td>\n",
       "      <td>ap√≥s fic sil√™nci cpi carl wizard retorn est un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-30 14:35:33</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>para de lamber fone de ouvido lista de doen√ßas...</td>\n",
       "      <td>[lamb, fon, ouv, list, doen√ß, transmiss, oral,...</td>\n",
       "      <td>lamb fon ouv list doen√ß transmiss oral prov am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-11 12:12:28</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>defini√ß√£o de vacina √© um tipo de subst√¢ncia v√≠...</td>\n",
       "      <td>[defin, vacin, tip, subst, bact√©r, introduz, c...</td>\n",
       "      <td>defin vacin tip subst bact√©r introduz corp pes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-11-19 14:52:06</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>por que o iphone √© mais seguro contra v√≠rus</td>\n",
       "      <td>[iphon, segur, contr, ]</td>\n",
       "      <td>iphon segur contr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-12-28 23:09:10</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>covid t√° a estragar completamente tudo</td>\n",
       "      <td>[estrag, complet, tud, ]</td>\n",
       "      <td>estrag complet tud</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            created_at sentiment  \\\n",
       "0  2021-07-04 22:17:21  Positivo   \n",
       "1  2019-11-30 14:35:33  Negativo   \n",
       "2  2022-01-11 12:12:28  Negativo   \n",
       "3  2019-11-19 14:52:06  Positivo   \n",
       "4  2021-12-28 23:09:10  Negativo   \n",
       "\n",
       "                                          normalized  \\\n",
       "0  ap√≥s ficar em sil√™ncio na cpi da covid carlos ...   \n",
       "1  para de lamber fone de ouvido lista de doen√ßas...   \n",
       "2  defini√ß√£o de vacina √© um tipo de subst√¢ncia v√≠...   \n",
       "3        por que o iphone √© mais seguro contra v√≠rus   \n",
       "4             covid t√° a estragar completamente tudo   \n",
       "\n",
       "                         normalized_text_stemm_emoji  \\\n",
       "0  [ap√≥s, fic, sil√™nci, cpi, carl, wizard, retorn...   \n",
       "1  [lamb, fon, ouv, list, doen√ß, transmiss, oral,...   \n",
       "2  [defin, vacin, tip, subst, bact√©r, introduz, c...   \n",
       "3                            [iphon, segur, contr, ]   \n",
       "4                           [estrag, complet, tud, ]   \n",
       "\n",
       "                                                stem  \n",
       "0  ap√≥s fic sil√™nci cpi carl wizard retorn est un...  \n",
       "1  lamb fon ouv list doen√ß transmiss oral prov am...  \n",
       "2  defin vacin tip subst bact√©r introduz corp pes...  \n",
       "3                                 iphon segur contr   \n",
       "4                                estrag complet tud   "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['created_at', 'sentiment', 'normalized', 'normalized_text_stemm_emoji', 'stem']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e9657275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negativo</th>\n",
       "      <th>Neutro</th>\n",
       "      <th>Positivo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Negativo  Neutro  Positivo\n",
       "0              0       0         1\n",
       "1              1       0         0\n",
       "2              1       0         0\n",
       "3              0       0         1\n",
       "4              1       0         0\n",
       "...          ...     ...       ...\n",
       "199995         1       0         0\n",
       "199996         1       0         0\n",
       "199997         0       1         0\n",
       "199998         0       1         0\n",
       "199999         0       0         1\n",
       "\n",
       "[200000 rows x 3 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot = pd.get_dummies(df['sentiment'])\n",
    "one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c6505811",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c7b88d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>normalized</th>\n",
       "      <th>normalized_text_stemm_emoji</th>\n",
       "      <th>stem</th>\n",
       "      <th>Negativo</th>\n",
       "      <th>Neutro</th>\n",
       "      <th>Positivo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-04 22:17:21</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>ap√≥s ficar em sil√™ncio na cpi da covid carlos ...</td>\n",
       "      <td>[ap√≥s, fic, sil√™nci, cpi, carl, wizard, retorn...</td>\n",
       "      <td>ap√≥s fic sil√™nci cpi carl wizard retorn est un...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-30 14:35:33</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>para de lamber fone de ouvido lista de doen√ßas...</td>\n",
       "      <td>[lamb, fon, ouv, list, doen√ß, transmiss, oral,...</td>\n",
       "      <td>lamb fon ouv list doen√ß transmiss oral prov am...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-11 12:12:28</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>defini√ß√£o de vacina √© um tipo de subst√¢ncia v√≠...</td>\n",
       "      <td>[defin, vacin, tip, subst, bact√©r, introduz, c...</td>\n",
       "      <td>defin vacin tip subst bact√©r introduz corp pes...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-11-19 14:52:06</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>por que o iphone √© mais seguro contra v√≠rus</td>\n",
       "      <td>[iphon, segur, contr, ]</td>\n",
       "      <td>iphon segur contr</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-12-28 23:09:10</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>covid t√° a estragar completamente tudo</td>\n",
       "      <td>[estrag, complet, tud, ]</td>\n",
       "      <td>estrag complet tud</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>2021-03-19 00:21:33</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>mais um brasileiro v√≠tima desse v√≠rus e assass...</td>\n",
       "      <td>[brasil, v√≠tim, dess, assassin, incompet, dess...</td>\n",
       "      <td>brasil v√≠tim dess assassin incompet dess govern</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>2020-03-15 23:59:18</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>sinceramente jovens e adultos saud√°veis que po...</td>\n",
       "      <td>[sinc, jov, adult, saud, pod, ter, assintom√°, ...</td>\n",
       "      <td>sinc jov adult saud pod ter assintom√° cust sos...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>2020-10-29 23:03:29</td>\n",
       "      <td>Neutro</td>\n",
       "      <td>a hcq acelera a elimina√ß√£o do covid19 do organ...</td>\n",
       "      <td>[hcq, aceler, elimin, organ, dia, uso, result,...</td>\n",
       "      <td>hcq aceler elimin organ dia uso result elimin ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>2020-09-24 23:35:28</td>\n",
       "      <td>Neutro</td>\n",
       "      <td>e o futebol brasileiro discutindo a volta de p...</td>\n",
       "      <td>[futebol, brasil, discut, volt, p√∫blic, est√°di, ]</td>\n",
       "      <td>futebol brasil discut volt p√∫blic est√°di</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>2020-03-13 23:56:55</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>sinceramente to meio sem tempo pra esse tal de...</td>\n",
       "      <td>[sinc, mei, temp, tal, chei, cois, resolv, esp...</td>\n",
       "      <td>sinc mei temp tal chei cois resolv esper enten...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 created_at sentiment  \\\n",
       "0       2021-07-04 22:17:21  Positivo   \n",
       "1       2019-11-30 14:35:33  Negativo   \n",
       "2       2022-01-11 12:12:28  Negativo   \n",
       "3       2019-11-19 14:52:06  Positivo   \n",
       "4       2021-12-28 23:09:10  Negativo   \n",
       "...                     ...       ...   \n",
       "199995  2021-03-19 00:21:33  Negativo   \n",
       "199996  2020-03-15 23:59:18  Negativo   \n",
       "199997  2020-10-29 23:03:29    Neutro   \n",
       "199998  2020-09-24 23:35:28    Neutro   \n",
       "199999  2020-03-13 23:56:55  Positivo   \n",
       "\n",
       "                                               normalized  \\\n",
       "0       ap√≥s ficar em sil√™ncio na cpi da covid carlos ...   \n",
       "1       para de lamber fone de ouvido lista de doen√ßas...   \n",
       "2       defini√ß√£o de vacina √© um tipo de subst√¢ncia v√≠...   \n",
       "3             por que o iphone √© mais seguro contra v√≠rus   \n",
       "4                  covid t√° a estragar completamente tudo   \n",
       "...                                                   ...   \n",
       "199995  mais um brasileiro v√≠tima desse v√≠rus e assass...   \n",
       "199996  sinceramente jovens e adultos saud√°veis que po...   \n",
       "199997  a hcq acelera a elimina√ß√£o do covid19 do organ...   \n",
       "199998  e o futebol brasileiro discutindo a volta de p...   \n",
       "199999  sinceramente to meio sem tempo pra esse tal de...   \n",
       "\n",
       "                              normalized_text_stemm_emoji  \\\n",
       "0       [ap√≥s, fic, sil√™nci, cpi, carl, wizard, retorn...   \n",
       "1       [lamb, fon, ouv, list, doen√ß, transmiss, oral,...   \n",
       "2       [defin, vacin, tip, subst, bact√©r, introduz, c...   \n",
       "3                                 [iphon, segur, contr, ]   \n",
       "4                                [estrag, complet, tud, ]   \n",
       "...                                                   ...   \n",
       "199995  [brasil, v√≠tim, dess, assassin, incompet, dess...   \n",
       "199996  [sinc, jov, adult, saud, pod, ter, assintom√°, ...   \n",
       "199997  [hcq, aceler, elimin, organ, dia, uso, result,...   \n",
       "199998  [futebol, brasil, discut, volt, p√∫blic, est√°di, ]   \n",
       "199999  [sinc, mei, temp, tal, chei, cois, resolv, esp...   \n",
       "\n",
       "                                                     stem  Negativo  Neutro  \\\n",
       "0       ap√≥s fic sil√™nci cpi carl wizard retorn est un...         0       0   \n",
       "1       lamb fon ouv list doen√ß transmiss oral prov am...         1       0   \n",
       "2       defin vacin tip subst bact√©r introduz corp pes...         1       0   \n",
       "3                                      iphon segur contr          0       0   \n",
       "4                                     estrag complet tud          1       0   \n",
       "...                                                   ...       ...     ...   \n",
       "199995   brasil v√≠tim dess assassin incompet dess govern          1       0   \n",
       "199996  sinc jov adult saud pod ter assintom√° cust sos...         1       0   \n",
       "199997  hcq aceler elimin organ dia uso result elimin ...         0       1   \n",
       "199998          futebol brasil discut volt p√∫blic est√°di          0       1   \n",
       "199999  sinc mei temp tal chei cois resolv esper enten...         0       0   \n",
       "\n",
       "        Positivo  \n",
       "0              1  \n",
       "1              0  \n",
       "2              0  \n",
       "3              1  \n",
       "4              0  \n",
       "...          ...  \n",
       "199995         0  \n",
       "199996         0  \n",
       "199997         0  \n",
       "199998         0  \n",
       "199999         1  \n",
       "\n",
       "[200000 rows x 8 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1041154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(n=20000, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7d1785b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "Negativo    9497\n",
       "Neutro      5859\n",
       "Positivo    4644\n",
       "dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('sentiment').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0f91c97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: ktrain in /usr/local/lib/python3.7/site-packages (0.38.0)\n",
      "Requirement already satisfied: syntok>1.3.3 in /usr/local/lib/python3.7/site-packages (from ktrain) (1.4.4)\n",
      "Requirement already satisfied: fastprogress>=0.1.21 in /usr/local/lib/python3.7/site-packages (from ktrain) (1.0.3)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.7/site-packages (from ktrain) (1.3.5)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/site-packages (from ktrain) (1.0.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/site-packages (from ktrain) (23.2)\n",
      "Requirement already satisfied: langdetect in /usr/local/lib/python3.7/site-packages (from ktrain) (1.0.9)\n",
      "Requirement already satisfied: tika in /usr/local/lib/python3.7/site-packages (from ktrain) (2.6.0)\n",
      "Requirement already satisfied: transformers>=4.17.0 in /usr/local/lib/python3.7/site-packages (from ktrain) (4.30.2)\n",
      "Requirement already satisfied: keras-bert>=0.86.0 in /usr/local/lib/python3.7/site-packages (from ktrain) (0.89.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/site-packages (from ktrain) (2.31.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/site-packages (from ktrain) (1.3.2)\n",
      "Requirement already satisfied: chardet in /usr/local/lib/python3.7/site-packages (from ktrain) (5.2.0)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/site-packages (from ktrain) (0.1.99)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.7/site-packages (from ktrain) (3.5.3)\n",
      "Requirement already satisfied: cchardet in /usr/local/lib/python3.7/site-packages (from ktrain) (2.1.7)\n",
      "Requirement already satisfied: whoosh in /usr/local/lib/python3.7/site-packages (from ktrain) (2.7.4)\n",
      "Requirement already satisfied: jieba in /usr/local/lib/python3.7/site-packages (from ktrain) (0.42.1)\n",
      "Requirement already satisfied: keras-transformer==0.40.0 in /usr/local/lib/python3.7/site-packages (from keras-bert>=0.86.0->ktrain) (0.40.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/site-packages (from keras-bert>=0.86.0->ktrain) (1.21.6)\n",
      "Requirement already satisfied: keras-multi-head==0.29.0 in /usr/local/lib/python3.7/site-packages (from keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.29.0)\n",
      "Requirement already satisfied: keras-position-wise-feed-forward==0.8.0 in /usr/local/lib/python3.7/site-packages (from keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.8.0)\n",
      "Requirement already satisfied: keras-layer-normalization==0.16.0 in /usr/local/lib/python3.7/site-packages (from keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.16.0)\n",
      "Requirement already satisfied: keras-embed-sim==0.10.0 in /usr/local/lib/python3.7/site-packages (from keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.10.0)\n",
      "Requirement already satisfied: keras-pos-embd==0.13.0 in /usr/local/lib/python3.7/site-packages (from keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.13.0)\n",
      "Requirement already satisfied: keras-self-attention==0.51.0 in /usr/local/lib/python3.7/site-packages (from keras-multi-head==0.29.0->keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.51.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/site-packages (from matplotlib>=3.0.0->ktrain) (9.5.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/site-packages (from matplotlib>=3.0.0->ktrain) (1.4.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.7/site-packages (from matplotlib>=3.0.0->ktrain) (4.38.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/site-packages (from matplotlib>=3.0.0->ktrain) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/site-packages (from matplotlib>=3.0.0->ktrain) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/site-packages (from matplotlib>=3.0.0->ktrain) (3.1.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/site-packages (from pandas>=1.0.1->ktrain) (2023.3.post1)\n",
      "Requirement already satisfied: regex>2016 in /usr/local/lib/python3.7/site-packages (from syntok>1.3.3->ktrain) (2023.10.3)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/site-packages (from transformers>=4.17.0->ktrain) (4.2.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.7/site-packages (from transformers>=4.17.0->ktrain) (0.4.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/site-packages (from transformers>=4.17.0->ktrain) (3.12.2)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/site-packages (from transformers>=4.17.0->ktrain) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/site-packages (from transformers>=4.17.0->ktrain) (4.66.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/site-packages (from transformers>=4.17.0->ktrain) (6.0.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.7/site-packages (from transformers>=4.17.0->ktrain) (0.16.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/site-packages (from langdetect->ktrain) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.7/site-packages (from requests->ktrain) (3.3.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests->ktrain) (1.26.17)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests->ktrain) (2023.7.22)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests->ktrain) (3.4)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/site-packages (from scikit-learn->ktrain) (1.7.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/site-packages (from scikit-learn->ktrain) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/site-packages (from tika->ktrain) (57.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers>=4.17.0->ktrain) (4.7.1)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers>=4.17.0->ktrain) (2023.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/site-packages (from importlib-metadata->transformers>=4.17.0->ktrain) (3.15.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ktrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "51368c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ktrain\n",
    "from ktrain import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b9d5614b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['normalized'].values, \n",
    "    df['sentiment'].values, \n",
    "    test_size=0.20, \n",
    "    random_state=42,\n",
    "    stratify=df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3d9f377c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X_train.tolist()\n",
    "y_train = y_train.tolist()\n",
    "x_test = X_test.tolist()\n",
    "y_test = y_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9eedf8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing train...\n",
      "language: pt\n",
      "train sequence lengths:\n",
      "\tmean : 19\n",
      "\t95percentile : 42\n",
      "\t99percentile : 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ktrain/utils.py:745: UserWarning: class_names argument was ignored, as they were extracted from string labels in dataset\n",
      "  \"class_names argument was ignored, as they were extracted from string labels in dataset\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "preprocessing test...\n",
      "language: pt\n",
      "test sequence lengths:\n",
      "\tmean : 19\n",
      "\t95percentile : 43\n",
      "\t99percentile : 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task: text classification\n"
     ]
    }
   ],
   "source": [
    "trn, val, preproc = text.texts_from_array(x_train=x_train, y_train=y_train,\n",
    "                                          x_test=x_test, y_test=y_test,\n",
    "                                          class_names=df['sentiment'].unique().tolist(),\n",
    "                                          preprocess_mode='distilbert',\n",
    "                                          maxlen=350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3d58ceef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "maxlen is 350\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "model = text.text_classifier('distilbert', train_data=trn, preproc=preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5148da81",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = ktrain.get_learner(model, train_data=trn, val_data=val, batch_size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "498a53ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "begin training using onecycle policy with max lr of 3e-05...\n",
      "Epoch 1/4\n",
      "2667/2667 [==============================] - 6567s 2s/step - loss: 0.7839 - accuracy: 0.6532 - val_loss: 0.5258 - val_accuracy: 0.7987\n",
      "Epoch 2/4\n",
      "2667/2667 [==============================] - 6573s 2s/step - loss: 0.4640 - accuracy: 0.8334 - val_loss: 0.4179 - val_accuracy: 0.8510\n",
      "Epoch 3/4\n",
      "2667/2667 [==============================] - 6570s 2s/step - loss: 0.3079 - accuracy: 0.8967 - val_loss: 0.3908 - val_accuracy: 0.8748\n",
      "Epoch 4/4\n",
      "2667/2667 [==============================] - 6567s 2s/step - loss: 0.1474 - accuracy: 0.9524 - val_loss: 0.3964 - val_accuracy: 0.8830\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1fc210f690>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit_onecycle(3e-5, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d89618f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 87s 696ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negativo       0.90      0.93      0.91      1899\n",
      "      Neutro       0.90      0.86      0.88      1172\n",
      "    Positivo       0.83      0.83      0.83       929\n",
      "\n",
      "    accuracy                           0.88      4000\n",
      "   macro avg       0.88      0.87      0.87      4000\n",
      "weighted avg       0.88      0.88      0.88      4000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1757,   56,   86],\n",
       "       [  92, 1006,   74],\n",
       "       [ 108,   52,  769]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.validate(class_names=preproc.get_classes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "634d20a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/transformers/generation/tf_utils.py:465: UserWarning: `seed_generator` is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\"`seed_generator` is deprecated and will be removed in a future version.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...classifier\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...distilbert\n",
      "......embeddings\n",
      ".........LayerNorm\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      ".........dropout\n",
      "............vars\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......transformer\n",
      ".........layer\n",
      "............tf_transformer_block\n",
      "...............attention\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................k_lin\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................out_lin\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................q_lin\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................v_lin\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............dropout\n",
      "..................vars\n",
      "...............ffn\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................lin1\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................lin2\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............output_layer_norm\n",
      "..................vars\n",
      ".....................0\n",
      ".....................1\n",
      "...............sa_layer_norm\n",
      "..................vars\n",
      ".....................0\n",
      ".....................1\n",
      "...............vars\n",
      "............tf_transformer_block_1\n",
      "...............attention\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................k_lin\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................out_lin\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................q_lin\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................v_lin\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............dropout\n",
      "..................vars\n",
      "...............ffn\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................lin1\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................lin2\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............output_layer_norm\n",
      "..................vars\n",
      ".....................0\n",
      ".....................1\n",
      "...............sa_layer_norm\n",
      "..................vars\n",
      ".....................0\n",
      ".....................1\n",
      "...............vars\n",
      "............tf_transformer_block_2\n",
      "...............attention\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................k_lin\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................out_lin\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................q_lin\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................v_lin\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............dropout\n",
      "..................vars\n",
      "...............ffn\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................lin1\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................lin2\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............output_layer_norm\n",
      "..................vars\n",
      ".....................0\n",
      ".....................1\n",
      "...............sa_layer_norm\n",
      "..................vars\n",
      ".....................0\n",
      ".....................1\n",
      "...............vars\n",
      "............tf_transformer_block_3\n",
      "...............attention\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................k_lin\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................out_lin\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................q_lin\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................v_lin\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............dropout\n",
      "..................vars\n",
      "...............ffn\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................lin1\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................lin2\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............output_layer_norm\n",
      "..................vars\n",
      ".....................0\n",
      ".....................1\n",
      "...............sa_layer_norm\n",
      "..................vars\n",
      ".....................0\n",
      ".....................1\n",
      "...............vars\n",
      "............tf_transformer_block_4\n",
      "...............attention\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................k_lin\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................out_lin\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................q_lin\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................v_lin\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............dropout\n",
      "..................vars\n",
      "...............ffn\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................lin1\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................lin2\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............output_layer_norm\n",
      "..................vars\n",
      ".....................0\n",
      ".....................1\n",
      "...............sa_layer_norm\n",
      "..................vars\n",
      ".....................0\n",
      ".....................1\n",
      "...............vars\n",
      "............tf_transformer_block_5\n",
      "...............attention\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................k_lin\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................out_lin\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................q_lin\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................v_lin\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............dropout\n",
      "..................vars\n",
      "...............ffn\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................lin1\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................lin2\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............output_layer_norm\n",
      "..................vars\n",
      ".....................0\n",
      ".....................1\n",
      "...............sa_layer_norm\n",
      "..................vars\n",
      ".....................0\n",
      ".....................1\n",
      "...............vars\n",
      ".........vars\n",
      "......vars\n",
      "...dropout\n",
      "......vars\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...metrics\n",
      "......mean\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......mean_metric_wrapper\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "variables.h5                                   2023-10-09 11:31:26    541526224\n",
      "config.json                                    2023-10-09 11:31:25         2050\n",
      "metadata.json                                  2023-10-09 11:31:25           64\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "filename = 'finalized_model_bert.sav'\n",
    "pickle.dump(learner, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbbe4aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
