{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8c9626ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: emoji in /usr/local/lib/python3.7/site-packages (2.8.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8bca4d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "43b1286b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>normalized_text_stemm_emoji</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-04 22:17:21</td>\n",
       "      <td>RT @emirsader: Após ficar em silêncio na CPI d...</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>[após, fic, silênci, cpi, carl, wizard, retorn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-30 14:35:33</td>\n",
       "      <td>RT @VittorGuidoni: para de lamber fone de ouvi...</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>[lamb, fon, ouv, list, doenç, transmiss, oral,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-11 12:12:28</td>\n",
       "      <td>@exposed_exposer @CarlaZambelli38 @andrizek De...</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>[defin, vacin, tip, subst, bactér, introduz, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-11-19 14:52:06</td>\n",
       "      <td>RT @canaltech: Por que o iPhone é mais seguro ...</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>[iphon, segur, contr, ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-12-28 23:09:10</td>\n",
       "      <td>RT @mariareinhardtt: covid tá a estragar compl...</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>[estrag, complet, tud, ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            created_at                                               text  \\\n",
       "0  2021-07-04 22:17:21  RT @emirsader: Após ficar em silêncio na CPI d...   \n",
       "1  2019-11-30 14:35:33  RT @VittorGuidoni: para de lamber fone de ouvi...   \n",
       "2  2022-01-11 12:12:28  @exposed_exposer @CarlaZambelli38 @andrizek De...   \n",
       "3  2019-11-19 14:52:06  RT @canaltech: Por que o iPhone é mais seguro ...   \n",
       "4  2021-12-28 23:09:10  RT @mariareinhardtt: covid tá a estragar compl...   \n",
       "\n",
       "  sentiment                        normalized_text_stemm_emoji  \n",
       "0  Positivo  [após, fic, silênci, cpi, carl, wizard, retorn...  \n",
       "1  Negativo  [lamb, fon, ouv, list, doenç, transmiss, oral,...  \n",
       "2  Negativo  [defin, vacin, tip, subst, bactér, introduz, c...  \n",
       "3  Positivo                            [iphon, segur, contr, ]  \n",
       "4  Negativo                           [estrag, complet, tud, ]  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data_pt_brazil_normalized_emoji_merged.csv',\n",
    "                                converters={\n",
    "                     \"normalized_text_stemm_emoji\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \")\n",
    "                 })\n",
    "df = df[['created_at', 'text', 'sentiment', 'normalized_text_stemm_emoji']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b253e66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_bank = {\n",
    "  \",:(\": \"😓\",\n",
    "  \",:)\": \"😅\",\n",
    "  \",:-(\": \"😓\",\n",
    "  \",:-)\": \"😅\",\n",
    "  \"0:)\": \"😇\",\n",
    "  \"0:-)\": \"😇\",\n",
    "  \"8-)\": \"😎\",\n",
    "  \":$\": \"😒\",\n",
    "  \":'(\": \"😢\",\n",
    "  \":')\": \"😂\",\n",
    "  \":'-(\": \"😢\",\n",
    "  \":'-)\": \"😂\",\n",
    "  \":'-D\": \"😂\",\n",
    "  \":'D\": \"😂\",\n",
    "  \":(\": \"😦\",\n",
    "  \":)\": \"😃\",\n",
    "  \":*\": \"😗\",\n",
    "  \":,'(\": \"😭\",\n",
    "  \":,'-(\": \"😭\",\n",
    "  \":,(\": \"😢\",\n",
    "  \":,)\": \"😂\",\n",
    "  \":,-(\": \"😢\",\n",
    "  \":,-)\": \"😂\",\n",
    "  \":,-D\": \"😂\",\n",
    "  \":,D\": \"😂\",\n",
    "  \":-$\": \"😒\",\n",
    "  \":-(\": \"😦\",\n",
    "  \":-)\": \"😃\",\n",
    "  \":-*\": \"😗\",\n",
    "  \":-/\": \"😕\",\n",
    "  \":-@\": \"😡\",\n",
    "  \":-D\": \"😄\",\n",
    "  \":-o\": \"😮\",\n",
    "  \":-O\": \"😮\",\n",
    "  \":-P\": \"😛\",\n",
    "  \":-S\": \"😒\",\n",
    "  \":-Z\": \"😒\",\n",
    "  \":-|\": \"😐\",\n",
    "  \":/\": \"😕\",\n",
    "  \":@\": \"😡\",\n",
    "  \":D\": \"😄\",\n",
    "  \":o\": \"😮\",\n",
    "  \":O\": \"😮\",\n",
    "  \":P\": \"😛\",\n",
    "  \":s\": \"😒\",\n",
    "  \":z\": \"😒\",\n",
    "  \":|\": \"😐\",\n",
    "  \";(\": \"😭\",\n",
    "  \";)\": \"😉\",\n",
    "  \";-(\": \"😭\",\n",
    "  \";-)\": \"😉\",\n",
    "  \"]:)\": \"😈\",\n",
    "  \"]:-)\": \"😈\",\n",
    "  \"B-)\": \"😎\",\n",
    "  \"o:)\": \"😇\",\n",
    "  \"O:)\": \"😇\",\n",
    "  \"O:-)\": \"😇\",\n",
    "  \"o:-)\": \"😇\",\n",
    "  \"X-)\": \"😆\",\n",
    "  \"x-)\": \"😆\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "26621668",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = ['rt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9bcfd786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string, unicodedata\n",
    "import nltk\n",
    "import emoji\n",
    "\n",
    "def extract_emojis(sample):\n",
    "    return ' '.join(c for c in sample if c in emoji.EMOJI_DATA).split()\n",
    "\n",
    "def remove_user_from_text(words):\n",
    "    return \" \".join(filter(lambda x:x[0]!='@', words.split()))\n",
    "\n",
    "def remove_double_space(sample):\n",
    "    return \" \".join(sample.split())\n",
    "\n",
    "def remove_URL(sample):\n",
    "    \"\"\"Remove URLs from a sample string\"\"\"\n",
    "    return re.sub(r\"http\\S+\", \"\", sample)\n",
    "\n",
    "def to_lowercase(words):\n",
    "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
    "    return list(map(lambda x: x.lower(), words))\n",
    "\n",
    "def remove_punctuation(words):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def clean_text(sample):\n",
    "    emoji_pat = '[\\U0001F300-\\U0001F64F\\U0001F680-\\U0001F6FF\\u2600-\\u26FF\\u2700-\\u27BF]'\n",
    "    shrink_whitespace_reg = re.compile(r'\\s{2,}')\n",
    "    reg = re.compile(r'({})|[^a-zA-Z]'.format(emoji_pat)) # line a\n",
    "    result = reg.sub(lambda x: ' {} '.format(x.group(1)) if x.group(1) else ' ', sample)\n",
    "    return shrink_whitespace_reg.sub(' ', result)\n",
    "\n",
    "def replace_asci_emoji(sample):\n",
    "    address = sample\n",
    "    for k,v in emoji_bank.items():\n",
    "        address = address.replace(k, v)\n",
    "    return address\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stopwords_list:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def normalize(words):\n",
    "    words = remove_user_from_text(words)\n",
    "    words = to_lowercase(words.split())\n",
    "    words = remove_punctuation(words)\n",
    "    words = remove_stopwords(words)\n",
    "    return words\n",
    "\n",
    "def preprocess(sample):\n",
    "    sample = remove_URL(sample)\n",
    "    sample = replace_asci_emoji(sample)\n",
    "#     sample = clean_text(sample)\n",
    "    sample = remove_double_space(sample)\n",
    "    return normalize(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "379b391a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>normalized_text_stemm_emoji</th>\n",
       "      <th>normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-04 22:17:21</td>\n",
       "      <td>RT @emirsader: Após ficar em silêncio na CPI d...</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>[após, fic, silênci, cpi, carl, wizard, retorn...</td>\n",
       "      <td>após ficar em silêncio na cpi da covid carlos ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-30 14:35:33</td>\n",
       "      <td>RT @VittorGuidoni: para de lamber fone de ouvi...</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>[lamb, fon, ouv, list, doenç, transmiss, oral,...</td>\n",
       "      <td>para de lamber fone de ouvido lista de doenças...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-11 12:12:28</td>\n",
       "      <td>@exposed_exposer @CarlaZambelli38 @andrizek De...</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>[defin, vacin, tip, subst, bactér, introduz, c...</td>\n",
       "      <td>definição de vacina é um tipo de substância ví...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-11-19 14:52:06</td>\n",
       "      <td>RT @canaltech: Por que o iPhone é mais seguro ...</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>[iphon, segur, contr, ]</td>\n",
       "      <td>por que o iphone é mais seguro contra vírus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-12-28 23:09:10</td>\n",
       "      <td>RT @mariareinhardtt: covid tá a estragar compl...</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>[estrag, complet, tud, ]</td>\n",
       "      <td>covid tá a estragar completamente tudo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            created_at                                               text  \\\n",
       "0  2021-07-04 22:17:21  RT @emirsader: Após ficar em silêncio na CPI d...   \n",
       "1  2019-11-30 14:35:33  RT @VittorGuidoni: para de lamber fone de ouvi...   \n",
       "2  2022-01-11 12:12:28  @exposed_exposer @CarlaZambelli38 @andrizek De...   \n",
       "3  2019-11-19 14:52:06  RT @canaltech: Por que o iPhone é mais seguro ...   \n",
       "4  2021-12-28 23:09:10  RT @mariareinhardtt: covid tá a estragar compl...   \n",
       "\n",
       "  sentiment                        normalized_text_stemm_emoji  \\\n",
       "0  Positivo  [após, fic, silênci, cpi, carl, wizard, retorn...   \n",
       "1  Negativo  [lamb, fon, ouv, list, doenç, transmiss, oral,...   \n",
       "2  Negativo  [defin, vacin, tip, subst, bactér, introduz, c...   \n",
       "3  Positivo                            [iphon, segur, contr, ]   \n",
       "4  Negativo                           [estrag, complet, tud, ]   \n",
       "\n",
       "                                          normalized  \n",
       "0  após ficar em silêncio na cpi da covid carlos ...  \n",
       "1  para de lamber fone de ouvido lista de doenças...  \n",
       "2  definição de vacina é um tipo de substância ví...  \n",
       "3        por que o iphone é mais seguro contra vírus  \n",
       "4             covid tá a estragar completamente tudo  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['normalized'] = df.apply(lambda x: \" \".join(preprocess(x['text'])), axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4396900d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "Negativo    93560\n",
       "Neutro      58975\n",
       "Positivo    47465\n",
       "dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('sentiment').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "10aced97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stem'] = df['normalized_text_stemm_emoji'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f9a926b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>normalized</th>\n",
       "      <th>normalized_text_stemm_emoji</th>\n",
       "      <th>stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-04 22:17:21</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>após ficar em silêncio na cpi da covid carlos ...</td>\n",
       "      <td>[após, fic, silênci, cpi, carl, wizard, retorn...</td>\n",
       "      <td>após fic silênci cpi carl wizard retorn est un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-30 14:35:33</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>para de lamber fone de ouvido lista de doenças...</td>\n",
       "      <td>[lamb, fon, ouv, list, doenç, transmiss, oral,...</td>\n",
       "      <td>lamb fon ouv list doenç transmiss oral prov am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-11 12:12:28</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>definição de vacina é um tipo de substância ví...</td>\n",
       "      <td>[defin, vacin, tip, subst, bactér, introduz, c...</td>\n",
       "      <td>defin vacin tip subst bactér introduz corp pes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-11-19 14:52:06</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>por que o iphone é mais seguro contra vírus</td>\n",
       "      <td>[iphon, segur, contr, ]</td>\n",
       "      <td>iphon segur contr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-12-28 23:09:10</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>covid tá a estragar completamente tudo</td>\n",
       "      <td>[estrag, complet, tud, ]</td>\n",
       "      <td>estrag complet tud</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            created_at sentiment  \\\n",
       "0  2021-07-04 22:17:21  Positivo   \n",
       "1  2019-11-30 14:35:33  Negativo   \n",
       "2  2022-01-11 12:12:28  Negativo   \n",
       "3  2019-11-19 14:52:06  Positivo   \n",
       "4  2021-12-28 23:09:10  Negativo   \n",
       "\n",
       "                                          normalized  \\\n",
       "0  após ficar em silêncio na cpi da covid carlos ...   \n",
       "1  para de lamber fone de ouvido lista de doenças...   \n",
       "2  definição de vacina é um tipo de substância ví...   \n",
       "3        por que o iphone é mais seguro contra vírus   \n",
       "4             covid tá a estragar completamente tudo   \n",
       "\n",
       "                         normalized_text_stemm_emoji  \\\n",
       "0  [após, fic, silênci, cpi, carl, wizard, retorn...   \n",
       "1  [lamb, fon, ouv, list, doenç, transmiss, oral,...   \n",
       "2  [defin, vacin, tip, subst, bactér, introduz, c...   \n",
       "3                            [iphon, segur, contr, ]   \n",
       "4                           [estrag, complet, tud, ]   \n",
       "\n",
       "                                                stem  \n",
       "0  após fic silênci cpi carl wizard retorn est un...  \n",
       "1  lamb fon ouv list doenç transmiss oral prov am...  \n",
       "2  defin vacin tip subst bactér introduz corp pes...  \n",
       "3                                 iphon segur contr   \n",
       "4                                estrag complet tud   "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['created_at', 'sentiment', 'normalized', 'normalized_text_stemm_emoji', 'stem']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e9657275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negativo</th>\n",
       "      <th>Neutro</th>\n",
       "      <th>Positivo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Negativo  Neutro  Positivo\n",
       "0              0       0         1\n",
       "1              1       0         0\n",
       "2              1       0         0\n",
       "3              0       0         1\n",
       "4              1       0         0\n",
       "...          ...     ...       ...\n",
       "199995         1       0         0\n",
       "199996         1       0         0\n",
       "199997         0       1         0\n",
       "199998         0       1         0\n",
       "199999         0       0         1\n",
       "\n",
       "[200000 rows x 3 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot = pd.get_dummies(df['sentiment'])\n",
    "one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c6505811",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c7b88d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>normalized</th>\n",
       "      <th>normalized_text_stemm_emoji</th>\n",
       "      <th>stem</th>\n",
       "      <th>Negativo</th>\n",
       "      <th>Neutro</th>\n",
       "      <th>Positivo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-04 22:17:21</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>após ficar em silêncio na cpi da covid carlos ...</td>\n",
       "      <td>[após, fic, silênci, cpi, carl, wizard, retorn...</td>\n",
       "      <td>após fic silênci cpi carl wizard retorn est un...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-30 14:35:33</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>para de lamber fone de ouvido lista de doenças...</td>\n",
       "      <td>[lamb, fon, ouv, list, doenç, transmiss, oral,...</td>\n",
       "      <td>lamb fon ouv list doenç transmiss oral prov am...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-11 12:12:28</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>definição de vacina é um tipo de substância ví...</td>\n",
       "      <td>[defin, vacin, tip, subst, bactér, introduz, c...</td>\n",
       "      <td>defin vacin tip subst bactér introduz corp pes...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-11-19 14:52:06</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>por que o iphone é mais seguro contra vírus</td>\n",
       "      <td>[iphon, segur, contr, ]</td>\n",
       "      <td>iphon segur contr</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-12-28 23:09:10</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>covid tá a estragar completamente tudo</td>\n",
       "      <td>[estrag, complet, tud, ]</td>\n",
       "      <td>estrag complet tud</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>2021-03-19 00:21:33</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>mais um brasileiro vítima desse vírus e assass...</td>\n",
       "      <td>[brasil, vítim, dess, assassin, incompet, dess...</td>\n",
       "      <td>brasil vítim dess assassin incompet dess govern</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>2020-03-15 23:59:18</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>sinceramente jovens e adultos saudáveis que po...</td>\n",
       "      <td>[sinc, jov, adult, saud, pod, ter, assintomá, ...</td>\n",
       "      <td>sinc jov adult saud pod ter assintomá cust sos...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>2020-10-29 23:03:29</td>\n",
       "      <td>Neutro</td>\n",
       "      <td>a hcq acelera a eliminação do covid19 do organ...</td>\n",
       "      <td>[hcq, aceler, elimin, organ, dia, uso, result,...</td>\n",
       "      <td>hcq aceler elimin organ dia uso result elimin ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>2020-09-24 23:35:28</td>\n",
       "      <td>Neutro</td>\n",
       "      <td>e o futebol brasileiro discutindo a volta de p...</td>\n",
       "      <td>[futebol, brasil, discut, volt, públic, estádi, ]</td>\n",
       "      <td>futebol brasil discut volt públic estádi</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>2020-03-13 23:56:55</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>sinceramente to meio sem tempo pra esse tal de...</td>\n",
       "      <td>[sinc, mei, temp, tal, chei, cois, resolv, esp...</td>\n",
       "      <td>sinc mei temp tal chei cois resolv esper enten...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 created_at sentiment  \\\n",
       "0       2021-07-04 22:17:21  Positivo   \n",
       "1       2019-11-30 14:35:33  Negativo   \n",
       "2       2022-01-11 12:12:28  Negativo   \n",
       "3       2019-11-19 14:52:06  Positivo   \n",
       "4       2021-12-28 23:09:10  Negativo   \n",
       "...                     ...       ...   \n",
       "199995  2021-03-19 00:21:33  Negativo   \n",
       "199996  2020-03-15 23:59:18  Negativo   \n",
       "199997  2020-10-29 23:03:29    Neutro   \n",
       "199998  2020-09-24 23:35:28    Neutro   \n",
       "199999  2020-03-13 23:56:55  Positivo   \n",
       "\n",
       "                                               normalized  \\\n",
       "0       após ficar em silêncio na cpi da covid carlos ...   \n",
       "1       para de lamber fone de ouvido lista de doenças...   \n",
       "2       definição de vacina é um tipo de substância ví...   \n",
       "3             por que o iphone é mais seguro contra vírus   \n",
       "4                  covid tá a estragar completamente tudo   \n",
       "...                                                   ...   \n",
       "199995  mais um brasileiro vítima desse vírus e assass...   \n",
       "199996  sinceramente jovens e adultos saudáveis que po...   \n",
       "199997  a hcq acelera a eliminação do covid19 do organ...   \n",
       "199998  e o futebol brasileiro discutindo a volta de p...   \n",
       "199999  sinceramente to meio sem tempo pra esse tal de...   \n",
       "\n",
       "                              normalized_text_stemm_emoji  \\\n",
       "0       [após, fic, silênci, cpi, carl, wizard, retorn...   \n",
       "1       [lamb, fon, ouv, list, doenç, transmiss, oral,...   \n",
       "2       [defin, vacin, tip, subst, bactér, introduz, c...   \n",
       "3                                 [iphon, segur, contr, ]   \n",
       "4                                [estrag, complet, tud, ]   \n",
       "...                                                   ...   \n",
       "199995  [brasil, vítim, dess, assassin, incompet, dess...   \n",
       "199996  [sinc, jov, adult, saud, pod, ter, assintomá, ...   \n",
       "199997  [hcq, aceler, elimin, organ, dia, uso, result,...   \n",
       "199998  [futebol, brasil, discut, volt, públic, estádi, ]   \n",
       "199999  [sinc, mei, temp, tal, chei, cois, resolv, esp...   \n",
       "\n",
       "                                                     stem  Negativo  Neutro  \\\n",
       "0       após fic silênci cpi carl wizard retorn est un...         0       0   \n",
       "1       lamb fon ouv list doenç transmiss oral prov am...         1       0   \n",
       "2       defin vacin tip subst bactér introduz corp pes...         1       0   \n",
       "3                                      iphon segur contr          0       0   \n",
       "4                                     estrag complet tud          1       0   \n",
       "...                                                   ...       ...     ...   \n",
       "199995   brasil vítim dess assassin incompet dess govern          1       0   \n",
       "199996  sinc jov adult saud pod ter assintomá cust sos...         1       0   \n",
       "199997  hcq aceler elimin organ dia uso result elimin ...         0       1   \n",
       "199998          futebol brasil discut volt públic estádi          0       1   \n",
       "199999  sinc mei temp tal chei cois resolv esper enten...         0       0   \n",
       "\n",
       "        Positivo  \n",
       "0              1  \n",
       "1              0  \n",
       "2              0  \n",
       "3              1  \n",
       "4              0  \n",
       "...          ...  \n",
       "199995         0  \n",
       "199996         0  \n",
       "199997         0  \n",
       "199998         0  \n",
       "199999         1  \n",
       "\n",
       "[200000 rows x 8 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1041154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(n=20000, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7d1785b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "Negativo    9497\n",
       "Neutro      5859\n",
       "Positivo    4644\n",
       "dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('sentiment').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0f91c97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: ktrain in /usr/local/lib/python3.7/site-packages (0.38.0)\n",
      "Requirement already satisfied: syntok>1.3.3 in /usr/local/lib/python3.7/site-packages (from ktrain) (1.4.4)\n",
      "Requirement already satisfied: fastprogress>=0.1.21 in /usr/local/lib/python3.7/site-packages (from ktrain) (1.0.3)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.7/site-packages (from ktrain) (1.3.5)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/site-packages (from ktrain) (1.0.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/site-packages (from ktrain) (23.2)\n",
      "Requirement already satisfied: langdetect in /usr/local/lib/python3.7/site-packages (from ktrain) (1.0.9)\n",
      "Requirement already satisfied: tika in /usr/local/lib/python3.7/site-packages (from ktrain) (2.6.0)\n",
      "Requirement already satisfied: transformers>=4.17.0 in /usr/local/lib/python3.7/site-packages (from ktrain) (4.30.2)\n",
      "Requirement already satisfied: keras-bert>=0.86.0 in /usr/local/lib/python3.7/site-packages (from ktrain) (0.89.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/site-packages (from ktrain) (2.31.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/site-packages (from ktrain) (1.3.2)\n",
      "Requirement already satisfied: chardet in /usr/local/lib/python3.7/site-packages (from ktrain) (5.2.0)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/site-packages (from ktrain) (0.1.99)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.7/site-packages (from ktrain) (3.5.3)\n",
      "Requirement already satisfied: cchardet in /usr/local/lib/python3.7/site-packages (from ktrain) (2.1.7)\n",
      "Requirement already satisfied: whoosh in /usr/local/lib/python3.7/site-packages (from ktrain) (2.7.4)\n",
      "Requirement already satisfied: jieba in /usr/local/lib/python3.7/site-packages (from ktrain) (0.42.1)\n",
      "Requirement already satisfied: keras-transformer==0.40.0 in /usr/local/lib/python3.7/site-packages (from keras-bert>=0.86.0->ktrain) (0.40.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/site-packages (from keras-bert>=0.86.0->ktrain) (1.21.6)\n",
      "Requirement already satisfied: keras-multi-head==0.29.0 in /usr/local/lib/python3.7/site-packages (from keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.29.0)\n",
      "Requirement already satisfied: keras-position-wise-feed-forward==0.8.0 in /usr/local/lib/python3.7/site-packages (from keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.8.0)\n",
      "Requirement already satisfied: keras-layer-normalization==0.16.0 in /usr/local/lib/python3.7/site-packages (from keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.16.0)\n",
      "Requirement already satisfied: keras-embed-sim==0.10.0 in /usr/local/lib/python3.7/site-packages (from keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.10.0)\n",
      "Requirement already satisfied: keras-pos-embd==0.13.0 in /usr/local/lib/python3.7/site-packages (from keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.13.0)\n",
      "Requirement already satisfied: keras-self-attention==0.51.0 in /usr/local/lib/python3.7/site-packages (from keras-multi-head==0.29.0->keras-transformer==0.40.0->keras-bert>=0.86.0->ktrain) (0.51.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/site-packages (from matplotlib>=3.0.0->ktrain) (9.5.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/site-packages (from matplotlib>=3.0.0->ktrain) (1.4.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.7/site-packages (from matplotlib>=3.0.0->ktrain) (4.38.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/site-packages (from matplotlib>=3.0.0->ktrain) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/site-packages (from matplotlib>=3.0.0->ktrain) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/site-packages (from matplotlib>=3.0.0->ktrain) (3.1.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/site-packages (from pandas>=1.0.1->ktrain) (2023.3.post1)\n",
      "Requirement already satisfied: regex>2016 in /usr/local/lib/python3.7/site-packages (from syntok>1.3.3->ktrain) (2023.10.3)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/site-packages (from transformers>=4.17.0->ktrain) (4.2.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.7/site-packages (from transformers>=4.17.0->ktrain) (0.4.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/site-packages (from transformers>=4.17.0->ktrain) (3.12.2)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/site-packages (from transformers>=4.17.0->ktrain) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/site-packages (from transformers>=4.17.0->ktrain) (4.66.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/site-packages (from transformers>=4.17.0->ktrain) (6.0.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.7/site-packages (from transformers>=4.17.0->ktrain) (0.16.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/site-packages (from langdetect->ktrain) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.7/site-packages (from requests->ktrain) (3.3.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests->ktrain) (1.26.17)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests->ktrain) (2023.7.22)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests->ktrain) (3.4)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/site-packages (from scikit-learn->ktrain) (1.7.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/site-packages (from scikit-learn->ktrain) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/site-packages (from tika->ktrain) (57.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers>=4.17.0->ktrain) (4.7.1)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers>=4.17.0->ktrain) (2023.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/site-packages (from importlib-metadata->transformers>=4.17.0->ktrain) (3.15.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ktrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "51368c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ktrain\n",
    "from ktrain import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b9d5614b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['normalized'].values, \n",
    "    df['sentiment'].values, \n",
    "    test_size=0.20, \n",
    "    random_state=42,\n",
    "    stratify=df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3d9f377c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X_train.tolist()\n",
    "y_train = y_train.tolist()\n",
    "x_test = X_test.tolist()\n",
    "y_test = y_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9eedf8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing train...\n",
      "language: pt\n",
      "train sequence lengths:\n",
      "\tmean : 19\n",
      "\t95percentile : 42\n",
      "\t99percentile : 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ktrain/utils.py:745: UserWarning: class_names argument was ignored, as they were extracted from string labels in dataset\n",
      "  \"class_names argument was ignored, as they were extracted from string labels in dataset\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "preprocessing test...\n",
      "language: pt\n",
      "test sequence lengths:\n",
      "\tmean : 19\n",
      "\t95percentile : 43\n",
      "\t99percentile : 51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task: text classification\n"
     ]
    }
   ],
   "source": [
    "trn, val, preproc = text.texts_from_array(x_train=x_train, y_train=y_train,\n",
    "                                          x_test=x_test, y_test=y_test,\n",
    "                                          class_names=df['sentiment'].unique().tolist(),\n",
    "                                          preprocess_mode='distilbert',\n",
    "                                          maxlen=350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3d58ceef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "maxlen is 350\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "model = text.text_classifier('distilbert', train_data=trn, preproc=preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5148da81",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = ktrain.get_learner(model, train_data=trn, val_data=val, batch_size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "498a53ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "begin training using onecycle policy with max lr of 3e-05...\n",
      "Epoch 1/4\n",
      "2667/2667 [==============================] - 6567s 2s/step - loss: 0.7839 - accuracy: 0.6532 - val_loss: 0.5258 - val_accuracy: 0.7987\n",
      "Epoch 2/4\n",
      "2667/2667 [==============================] - 6573s 2s/step - loss: 0.4640 - accuracy: 0.8334 - val_loss: 0.4179 - val_accuracy: 0.8510\n",
      "Epoch 3/4\n",
      "2667/2667 [==============================] - 6570s 2s/step - loss: 0.3079 - accuracy: 0.8967 - val_loss: 0.3908 - val_accuracy: 0.8748\n",
      "Epoch 4/4\n",
      "2667/2667 [==============================] - 6567s 2s/step - loss: 0.1474 - accuracy: 0.9524 - val_loss: 0.3964 - val_accuracy: 0.8830\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1fc210f690>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit_onecycle(3e-5, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d89618f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 87s 696ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negativo       0.90      0.93      0.91      1899\n",
      "      Neutro       0.90      0.86      0.88      1172\n",
      "    Positivo       0.83      0.83      0.83       929\n",
      "\n",
      "    accuracy                           0.88      4000\n",
      "   macro avg       0.88      0.87      0.87      4000\n",
      "weighted avg       0.88      0.88      0.88      4000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1757,   56,   86],\n",
       "       [  92, 1006,   74],\n",
       "       [ 108,   52,  769]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.validate(class_names=preproc.get_classes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "634d20a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/transformers/generation/tf_utils.py:465: UserWarning: `seed_generator` is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\"`seed_generator` is deprecated and will be removed in a future version.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...classifier\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...distilbert\n",
      "......embeddings\n",
      ".........LayerNorm\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      ".........dropout\n",
      "............vars\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......transformer\n",
      ".........layer\n",
      "............tf_transformer_block\n",
      "...............attention\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................k_lin\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................out_lin\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................q_lin\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................v_lin\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............dropout\n",
      "..................vars\n",
      "...............ffn\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................lin1\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................lin2\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............output_layer_norm\n",
      "..................vars\n",
      ".....................0\n",
      ".....................1\n",
      "...............sa_layer_norm\n",
      "..................vars\n",
      ".....................0\n",
      ".....................1\n",
      "...............vars\n",
      "............tf_transformer_block_1\n",
      "...............attention\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................k_lin\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................out_lin\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................q_lin\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................v_lin\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............dropout\n",
      "..................vars\n",
      "...............ffn\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................lin1\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................lin2\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............output_layer_norm\n",
      "..................vars\n",
      ".....................0\n",
      ".....................1\n",
      "...............sa_layer_norm\n",
      "..................vars\n",
      ".....................0\n",
      ".....................1\n",
      "...............vars\n",
      "............tf_transformer_block_2\n",
      "...............attention\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................k_lin\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................out_lin\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................q_lin\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................v_lin\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............dropout\n",
      "..................vars\n",
      "...............ffn\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................lin1\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................lin2\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............output_layer_norm\n",
      "..................vars\n",
      ".....................0\n",
      ".....................1\n",
      "...............sa_layer_norm\n",
      "..................vars\n",
      ".....................0\n",
      ".....................1\n",
      "...............vars\n",
      "............tf_transformer_block_3\n",
      "...............attention\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................k_lin\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................out_lin\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................q_lin\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................v_lin\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............dropout\n",
      "..................vars\n",
      "...............ffn\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................lin1\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................lin2\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............output_layer_norm\n",
      "..................vars\n",
      ".....................0\n",
      ".....................1\n",
      "...............sa_layer_norm\n",
      "..................vars\n",
      ".....................0\n",
      ".....................1\n",
      "...............vars\n",
      "............tf_transformer_block_4\n",
      "...............attention\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................k_lin\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................out_lin\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................q_lin\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................v_lin\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............dropout\n",
      "..................vars\n",
      "...............ffn\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................lin1\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................lin2\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............output_layer_norm\n",
      "..................vars\n",
      ".....................0\n",
      ".....................1\n",
      "...............sa_layer_norm\n",
      "..................vars\n",
      ".....................0\n",
      ".....................1\n",
      "...............vars\n",
      "............tf_transformer_block_5\n",
      "...............attention\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................k_lin\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................out_lin\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................q_lin\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................v_lin\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............dropout\n",
      "..................vars\n",
      "...............ffn\n",
      "..................dropout\n",
      ".....................vars\n",
      "..................lin1\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................lin2\n",
      ".....................vars\n",
      "........................0\n",
      "........................1\n",
      "..................vars\n",
      "...............output_layer_norm\n",
      "..................vars\n",
      ".....................0\n",
      ".....................1\n",
      "...............sa_layer_norm\n",
      "..................vars\n",
      ".....................0\n",
      ".....................1\n",
      "...............vars\n",
      ".........vars\n",
      "......vars\n",
      "...dropout\n",
      "......vars\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...metrics\n",
      "......mean\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......mean_metric_wrapper\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "variables.h5                                   2023-10-09 11:31:26    541526224\n",
      "config.json                                    2023-10-09 11:31:25         2050\n",
      "metadata.json                                  2023-10-09 11:31:25           64\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "filename = 'finalized_model_bert.sav'\n",
    "pickle.dump(learner, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbbe4aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
