{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ac52a31",
   "metadata": {},
   "source": [
    "### This Notebooks contains lexical exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "11131bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in /usr/local/lib/python3.7/site-packages (2.8.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: emosent-py in /usr/local/lib/python3.7/site-packages (0.1.7)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: dask in /usr/local/lib/python3.7/site-packages (2022.2.0)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.7/site-packages (from dask) (0.6.3)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.7/site-packages (from dask) (6.0.1)\n",
      "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.7/site-packages (from dask) (1.4.0)\n",
      "Requirement already satisfied: cloudpickle>=1.1.1 in /usr/local/lib/python3.7/site-packages (from dask) (2.2.1)\n",
      "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.7/site-packages (from dask) (0.12.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/site-packages (from dask) (23.1)\n",
      "Requirement already satisfied: locket in /usr/local/lib/python3.7/site-packages (from partd>=0.3.10->dask) (1.0.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji\n",
    "!pip install emosent-py\n",
    "!pip install dask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5212c1a",
   "metadata": {},
   "source": [
    "#### Loading Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1e7e8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../libs/leia/\")\n",
    "from leia import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "import emoji\n",
    "from emosent import get_emoji_sentiment_rank\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5c23e2",
   "metadata": {},
   "source": [
    "#### Loading Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dee7962e",
   "metadata": {},
   "outputs": [],
   "source": [
    "leia_classifier = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65fc53f",
   "metadata": {},
   "source": [
    "#### Custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eb105f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate_emoji(orig_str):\n",
    "    prev_emoji = None\n",
    "    remove_duplicate_emoji = []\n",
    "    try:\n",
    "        for c in orig_str:\n",
    "            if c in emoji.EMOJI_DATA.keys():\n",
    "                if prev_emoji == c:\n",
    "                    continue\n",
    "                prev_emoji = c\n",
    "            remove_duplicate_emoji.append(c)\n",
    "        return \"\".join(remove_duplicate_emoji)\n",
    "    except:\n",
    "        return orig_str\n",
    "\n",
    "def check_emoji_sentiment(orig_str):\n",
    "    neg = 0\n",
    "    neu = 0\n",
    "    pos = 0\n",
    "    sco = 0\n",
    "    \n",
    "    try:\n",
    "        emoji_list = emoji.distinct_emoji_list(orig_str)\n",
    "        if len(emoji_list) > 0:\n",
    "            for item in emoji_list:\n",
    "                \n",
    "                try:\n",
    "                    sentiment_rank = get_emoji_sentiment_rank(item)\n",
    "                    neg += sentiment_rank['negative']\n",
    "                    neu += sentiment_rank['neutral']\n",
    "                    pos += sentiment_rank['positive']\n",
    "                    sco += sentiment_rank['sentiment_score']\n",
    "                \n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        tot = neg + neu + pos \n",
    "        \n",
    "        return {\n",
    "            'neg': round(neg/tot,3),\n",
    "            'neu': round(neu/tot,3),\n",
    "            'pos': round(pos/tot,3),\n",
    "            'sco': round(sco/tot,3)\n",
    "        }\n",
    "    \n",
    "    except:\n",
    "        return {\n",
    "            'neg': round(neg,3),\n",
    "            'neu': round(neu,3),\n",
    "            'pos': round(pos,3),\n",
    "            'sco': round(sco,3)\n",
    "        }\n",
    "\n",
    "def check_text_sentiment(orig_str):\n",
    "    orig_str_without_emoji =  emoji.replace_emoji(remove_duplicate_emoji(orig_str), replace='')\n",
    "    sentiment_polarity = leia_classifier.polarity_scores(orig_str_without_emoji)\n",
    "    \n",
    "    return {\n",
    "            'neg': sentiment_polarity['neg'],\n",
    "            'neu': sentiment_polarity['neu'],\n",
    "            'pos': sentiment_polarity['pos'],\n",
    "            'compound': sentiment_polarity['compound'],\n",
    "    }\n",
    "\n",
    "def compound_sentiment(text_sentiment, emoji_sentiment):\n",
    "    compound = {\n",
    "        'neg': 0,\n",
    "        'neu': 0,\n",
    "        'pos': 0\n",
    "    }\n",
    "    tot = 0\n",
    "    for kind in compound.keys():\n",
    "        compound[kind] = text_sentiment[kind] + emoji_sentiment[kind]\n",
    "        tot += compound[kind]\n",
    "    return {k: round(v / tot,3) for k, v in compound.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "930178fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "d_type = {\n",
    "    'text': np.str,\n",
    "    'author_id': np.float64,\n",
    "    'conversation_id': np.float64,\n",
    "    'created_at': np.str,\n",
    "    'source': np.str,\n",
    "    'tweet_id': np.float64,\n",
    "    'geo_id': np.str,\n",
    "    'retweet_count': np.float64,\n",
    "    'reply_count': np.float64,\n",
    "    'like_count': np.float64,\n",
    "    'quote_count': np.float64,\n",
    "    'in_reply_to_user_id': np.float64,\n",
    "    'referenced_type': np.str,\n",
    "    'referenced_id': np.float64\n",
    "}\n",
    "\n",
    "# df = dd.read_csv('../../src/application/data/tweets_brazil.csv', dtype=d_type, error_bad_lines=False)  \n",
    "\n",
    "# df_tweets = pd.read_csv('../../src/application/data/tweets_portuguese.csv', sep=',', dtype=d_type, error_bad_lines=False, low_memory=False)\n",
    "\n",
    "chunksize = 10000\n",
    "for chunk in pd.read_csv('../../src/application/data/tweets_portuguese.csv', sep=',', dtype=d_type, error_bad_lines=False, chunksize=chunksize):\n",
    "    try:\n",
    "        chunk=chunk[['text', 'created_at']]\n",
    "        chunk['text'] = chunk['text'].apply(lambda x: remove_duplicate_emoji(x))\n",
    "        chunk['text_sentiment'] = chunk['text'].apply(lambda x: check_text_sentiment(str(x)))\n",
    "        chunk['sentiment_value'] = chunk.apply(lambda x: x['text_sentiment']['compound'], axis=1)\n",
    "        chunk=chunk[['text', 'created_at', 'text_sentiment', 'sentiment_value']]\n",
    "        chunk.to_csv(f'./data/{uuid.uuid4().hex}.csv', index=False, header=True)\n",
    "    except ParserError:\n",
    "        print(1)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d16320",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
